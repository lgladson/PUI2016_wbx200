{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pylab as pl\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime as dt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using curl-o to download the data, move it to PUIDATA, and read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3110k    0 3110k    0     0  7882k      0 --:--:-- --:--:-- --:--:-- 14.3M\n",
      "mv rows.csv /home/cusp/wbx200/PUIdata\n"
     ]
    }
   ],
   "source": [
    "#download, move data to $PUIDATA, and read data in \n",
    "!curl -O https://data.cityofnewyork.us/api/views/rgfe-8y2z/rows.csv\n",
    "cmd = \"mv rows.csv \" + os.getenv(\"PUIDATA\")\n",
    "#the line below is to check that my string is formatted right. I should remove it to make the notebook delivery ready\n",
    "print (cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11.6M  100 11.6M    0     0  26.4M      0 --:--:-- --:--:-- --:--:-- 26.8M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!curl -O http://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/mn_mappluto_16v1.zip\n",
    "os.system(\"unzip mn_mappluto_16v1.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing it in a subdirectory called \"Manhattan\" within PUIDATA.  NOTE: In Yao's code, Yao combined everything above into a function (\"getpluto\") that does exactly the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir /home/cusp/wbx200/PUIdata/Manhattan\n",
      "mv mn* MN* PLUTO* /home/cusp/wbx200/PUIdata/Manhattan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I want the files to be stored in a single directory so that the place is less messy\n",
    "# so I am creating a subdir of PUIdata and putting the unzipped files there. (Not required)\n",
    "cmd = \"mkdir \" + os.getenv(\"PUIDATA\") + \"/Manhattan\"\n",
    "print (cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "cmd = \"mv mn* MN* PLUTO* \" + os.getenv(\"PUIDATA\")+\"/Manhattan\"\n",
    "print (cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up two dataframes from the downloaded data (\"nrg\" and \"bsize\") and plotting a scatter matrix of the energy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrg = gp.GeoDataFrame.from_csv(os.getenv(\"PUIDATA\") + \"/Energy_and_Water_Data_Disclosure_for_Local_Law_84__2013_.csv\")\n",
    "# exploring the data a bit\n",
    "sfig = scatter_matrix (nrg, s=300, figsize=(10, 10), diagonal='kde')\n",
    "\n",
    "bsize = gp.GeoDataFrame.from_file(os.getenv(\"PUIDATA\") + \"/Manhattan/MNMapPLUTO.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsize.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping columns that aren't necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrg.drop(['Co-reported BBL Status',\n",
    "       'BBLs Co-reported',\n",
    "       'Reported NYC Building Identificaiton Numbers (BINs)', 'Street Number',\n",
    "       'Street Name', 'Borough', 'Zip Code',\n",
    "       'DOF Benchmarking Submission Status', \n",
    "       'Weather Normalized Site EUI(kBtu/ft2)', 'Source EUI(kBtu/ft2)',\n",
    "       'Weather Normalized Source EUI(kBtu/ft2)',\n",
    "       'Municipally Supplied Potable Water - Indoor Intensity (gal/ft²)',\n",
    "       'Automatic Water Benchmarking Eligible', 'Reported Water Method',\n",
    "       'ENERGY STAR Score', 'Total GHG Emissions(MtCO2e)',\n",
    "       'Direct GHG Emissions(MtCO2e)', 'Indirect GHG Emissions(MtCO2e)',\n",
    "       'DOF Property Floor Area (Buildngs and Parking)(ft2)',\n",
    "       'Primary Property Type - Self Selected', 'DOF Number of Buildings'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsize.drop(['APPBBL', 'APPDate', 'Address', 'AllZoning1', 'AllZoning2',\n",
    "       'AreaSource', 'AssessLand', 'AssessTot', 'BldgArea', 'BldgClass',\n",
    "       'BldgDepth', 'BldgFront', 'Block', 'BoroCode', 'Borough', 'BsmtCode',\n",
    "       'BuiltCode', 'BuiltFAR', 'CB2010', 'CD', 'CT2010', 'ComArea', 'CommFAR',\n",
    "       'CondoNo', 'Council', 'EDesigNum', 'Easements', 'ExemptLand',\n",
    "       'ExemptTot', 'Ext', 'FacilFAR', 'FactryArea', 'FireComp', 'GarageArea',\n",
    "       'HealthArea', 'HistDist', 'IrrLotCode', 'LandUse', 'Landmark', 'Lot',\n",
    "       'LotArea', 'LotDepth', 'LotFront', 'LotType', 'LtdHeight', 'MAPPLUTO_F',\n",
    "       'NumBldgs', 'NumFloors', 'OfficeArea', 'OtherArea', 'Overlay1',\n",
    "       'Overlay2', 'OwnerName', 'OwnerType', 'PLUTOMapID', 'PolicePrct',\n",
    "       'ProxCode', 'ResArea', 'ResidFAR', 'RetailArea', 'SHAPE_Area',\n",
    "       'SHAPE_Leng', 'SPDist1', 'SPDist2', 'Sanborn', 'SanitBoro', 'SanitDist',\n",
    "       'SanitSub', 'SchoolDist', 'SplitZone', 'StrgeArea', 'TaxMap',\n",
    "       'Tract2010', 'Version', 'XCoord', 'YCoord',\n",
    "       'YearAlter1', 'YearAlter2', 'ZMCode', 'ZipCode',\n",
    "       'ZoneDist1', 'ZoneDist2', 'ZoneDist3', 'ZoneDist4', 'ZoneMap',\n",
    "       'geometry'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the pd.to_numeric function that Kelsey brought up for HW6 - the \"coerce\" function is used to convert all non-numerical data to NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrg['Reported Property Floor Area (Building(s)) (ft²)'] = \\\n",
    "            pd.to_numeric(nrg['Reported Property Floor Area (Building(s)) (ft²)'], "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we rename a specific column to remove the spaces (to \"BBL\") and then use that as the basis for the merge between the two data sets.  Keep in mind that she mentioned three ways to do it: (HOW: inner, outer, and I forgot the other...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#renaming the quantity of interest \n",
    "#so i can refer to the column as an attribute if i want to while now i can't because the names contain spaces.\n",
    "#also I want the same name for the common column BBL in both dataframes for merging\n",
    "nrg.rename(columns={'NYC Borough, Block, and Lot (BBL)':'BBL'}, \n",
    "           inplace=True)\n",
    "nrg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bblnrgdata = pd.merge(nrg, bsize, how='inner', on=['BBL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She multiples area by kBtu/ft2 to get total energy per building, prints the min and max, and then plots it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## multiplying area by energy/area to get total energy per building\n",
    "bblnrgdata['nrg'] = bblnrgdata[\\\n",
    "    'Reported Property Floor Area (Building(s)) (ft²)'].astype(float) *\\\n",
    "                bblnrgdata['Site EUI(kBtu/ft2)'].astype(float)\n",
    "print (bblnrgdata.nrg[bblnrgdata.nrg>0].min())\n",
    "print (bblnrgdata.nrg.max())\n",
    "'''\n",
    "indx= s1.UnitsTotal>1000\n",
    "s1['UnitsTotal'][indx]=float('NaN')\n",
    "indx= s1.UnitsTotal>1000\n",
    "s1['UnitsTotal'][indx]=float('NaN')\n",
    "'''\n",
    "ax = bblnrgdata.plot(kind='scatter',x='nrg',y='UnitsTotal',\n",
    "                     marker='o', figsize=(10, 10),  \n",
    "                     xlim=(1000,1e11), ylim=(1,1000), fontsize=22)\n",
    "yl = ax.set_ylabel(\"Number of Units in Building\", fontsize=20)\n",
    "xl = ax.set_xlabel(\"Energy consumption per building (kBtu)\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She specifies limits to the axes to visualize the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cutting the limts in the plot to se if patterns emerge\n",
    "ax = bblnrgdata.plot(kind='scatter',x='nrg',y='UnitsTotal', \n",
    "                marker='o',  figsize=(10, 10),   \n",
    "                xlim=(1000,1e10), ylim=(1,1000))\n",
    "yl = ax.set_ylabel(\"Number of Units in Building\", fontsize=20)\n",
    "xl = ax.set_xlabel(\"Energy consumption per building (kBtu)\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She specifies maxima for energy and units (arbitrarily set limits and throw out \"outliers\"), and plot a LOG plot in order to show a better data pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bblnrgdataCut = bblnrgdata[(bblnrgdata.nrg > 1000) * (bblnrgdata.UnitsTotal>=10) * \n",
    "                           (bblnrgdata.UnitsTotal<1000)]\n",
    "\n",
    "ax = bblnrgdataCut.plot(kind='scatter', x='nrg', y='UnitsTotal', \n",
    "                   marker='o',  figsize=(16, 14), loglog=True)\n",
    "yl = ax.set_ylabel(\"Number of Units in Building\", fontsize=20)\n",
    "xl = ax.set_xlabel(\"Energy consumption per building (kBtu)\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She defines a chi square function with three inputs: 1) the data (that we have), 2) the model (the fit lines we are going to plot), 3) and the errors (which we are going to specify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chi2(data, model, errors = None):\n",
    "    '''Calculates the chi sq given data, model and errors\n",
    "    Arguments:\n",
    "    data: series of datapoints (endogenous variable)\n",
    "    model: series of predicted values corresponding to the observed data\n",
    "    errors: serie of errors (optional). \n",
    "    If errors are not passes all errors are set to 1\n",
    "    '''\n",
    "    if errors is None:\n",
    "        errors = np.ones_like(data)\n",
    "    if data.shape == model.shape and data.shape == errors.shape:\n",
    "        return (((data - model)**2) / errors**2).sum()\n",
    "    else: \n",
    "        print ('''ERROR:\n",
    "must pass arrays of identical dimension for data, model and (optional) error)''')\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She specifies errors on both nrg and unit data.  NRG data error is added in quadriture (since it's from two different sources) and unit error is just square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Assume that there is error in the reported energy. \n",
    "## but that is the product of two measured qusntities, each of which will have errors. \n",
    "## The minimum error is the squareroot of the value\n",
    "\n",
    "#errors on the measured quantities\n",
    "errorsnrg = np.sqrt((bblnrgdataCut['Reported Property Floor Area (Building(s)) (ft²)'])**2 +\\\n",
    "                (bblnrgdataCut['Site EUI(kBtu/ft2)']**2))\n",
    "\n",
    "## Assume count statistics in the number of units as well\n",
    "errorsunits = np.sqrt(bblnrgdataCut.UnitsTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She propogates the errors on the log plots (based off of Wiki) and specifies them within the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errorsInLogNrg = np.abs(errorsnrg / bblnrgdataCut.nrg / np.log(10))\n",
    "errorsInLogUnits = np.abs(errorsunits / bblnrgdataCut.UnitsTotal / np.log(10))\n",
    "\n",
    "bblnrgdataCut['errorsnrg'] =errorsInLogNrg\n",
    "bblnrgdataCut['errorsunits'] = errorsInLogUnits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She defines a line-fit function that has two inputs (x and y) and three outputs (slope, intercept of best fit, and the full model fit).  These three outputs are defined as p0, p1, and linmodel_0.  The scatter plot and linmodel_0 (the full model fit) are plotted in the figure.  The second section of code is EXACTLY the same as the previous, except the x and the y values are flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_line1(x, y):\n",
    "    \"\"\"Fits a line to data properly adding the dimensions required by statsmodels\n",
    "    Arguments:\n",
    "        x: series of exogenous variables\n",
    "        y: seried of endogenous variables\n",
    "    Output:\n",
    "        slope, intercept of best fit line, and the full model fit\n",
    "    \"\"\"\n",
    "    #print x\n",
    "    X = sm.add_constant(x)\n",
    "    #print X\n",
    "    model = sm.OLS(y, X, missing='drop') # ignores entires where x or y is NaN\n",
    "    fit = model.fit()\n",
    "    return fit.params[1], fit.params[0], fit # could also return stderr in each via fit.bse\n",
    "\n",
    "p1, p0, linmodel_0 = fit_line1(np.log10(bblnrgdataCut.nrg), \n",
    "                        np.log10(bblnrgdataCut.UnitsTotal))\n",
    "pl.figure(figsize=(10, 10))\n",
    "pl.scatter(np.log10(bblnrgdataCut.nrg), np.log10(bblnrgdataCut.UnitsTotal))\n",
    "plot(np.log10(bblnrgdataCut.nrg), linmodel_0.predict(), 'k')\n",
    "yl = pl.ylabel(\"log 10 Number of Units in Building\", fontsize=20)\n",
    "xl = pl.xlabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "linmodel_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1, p0, linmodel_1 = fit_line1(np.log10(bblnrgdataCut.UnitsTotal), \n",
    "                        np.log10(bblnrgdataCut.nrg))\n",
    "pl.figure(figsize=(10,10))\n",
    "pl.scatter(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg))\n",
    "plot(np.log10(bblnrgdataCut.UnitsTotal), linmodel_1.predict(), 'k')\n",
    "xl = pl.xlabel(\"log10 Number of Units in Building\", fontsize=20)\n",
    "yl = pl.ylabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "linmodel_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  She recreates the plots above, but this time with error included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(18, 14))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.errorbar(np.log10(bblnrgdataCut.nrg), np.log10(bblnrgdataCut.UnitsTotal), \n",
    "                 yerr=bblnrgdataCut.errorsunits, fmt='o')\n",
    "ax1.set_ylabel(\"log10 of Number of Units in Building\", fontsize=20)\n",
    "ax1.set_xlabel(\"building log10 of Energy  per  (kBtu)\", fontsize=20)\n",
    "ax1.set_title(\"Total units in building as function of Energy\")\n",
    "\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.errorbar(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg), \n",
    "                 yerr=bblnrgdataCut.errorsnrg, fmt='o')\n",
    "ax3.set_xlabel(\"log10 of Number of Units in Building\", fontsize=20)\n",
    "ax3.set_ylabel(\"building log10 of Energy  per  (kBtu)\", fontsize=20)\n",
    "ax3.set_title(\"Energy as function of total units in building\")\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.errorbar(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg), \n",
    "                 yerr=bblnrgdataCut.errorsnrg, fmt='o')\n",
    "ax4.set_xlabel(\"log10 of Number of Units in Building\", fontsize=20)\n",
    "ax4.set_ylabel(\"building log10 of Energy  per  (kBtu)\", fontsize=20)\n",
    "ax4.set_ylim(5,11)\n",
    "ax4.set_title(\"Energy as function of total units in building, zoom-in\")\n",
    "\n",
    "print (\"The largest error bar is for\")\n",
    "bblnrgdataCut[bblnrgdataCut.errorsnrg == bblnrgdataCut.errorsnrg.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She compares the chi-square values for all the different line fits that were plotted.  We are looking for the fits with the smallest chi-square values, but it varies depending on whether or not errors are involved.  She makes a point that errors MUST be included, since if we were just comparing the numbers (the residuals) there is nothing relating the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Units vs Energy residuals (no errors include): %.2f\"%\\\n",
    "       chi2(np.log10(bblnrgdataCut.UnitsTotal), linmodel_0.predict()))\n",
    "print (\"Energy vs Units residuals (no errors include): %.2f\"%\\\n",
    "        chi2(np.log10(bblnrgdataCut.nrg), linmodel_1.predict()))\n",
    "\n",
    "print (\"Units vs Energy chi square w IV error only: %.2f\"%\\\n",
    "       chi2(np.log10(bblnrgdataCut.UnitsTotal), linmodel_0.predict(), \n",
    "            errors = bblnrgdataCut.errorsunits))\n",
    "print (\"Energy vs Units chi square w IV error only: %.2f\"%\\\n",
    "        chi2(np.log10(bblnrgdataCut.nrg), linmodel_1.predict(), \n",
    "             errors = bblnrgdataCut.errorsnrg))\n",
    "\n",
    "print (\"Units vs Energy chi square: %.2f\"%\\\n",
    "       chi2(np.log10(bblnrgdataCut.UnitsTotal), linmodel_0.predict(), \n",
    "            errors = np.sqrt(bblnrgdataCut.errorsnrg**2 + bblnrgdataCut.errorsunits**2)))\n",
    "print (\"Energy vs Units chi square: %.2f\"%\\\n",
    "        chi2(np.log10(bblnrgdataCut.nrg), linmodel_1.predict(), \n",
    "             errors = np.sqrt(bblnrgdataCut.errorsnrg**2 + bblnrgdataCut.errorsunits**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She plots the second degree polynomial fit, the key here being that the formula is a function of NRG (y-intercept), units (x value), and units squared (x value squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I find the easiest way to use the formula package is to use a dataframe \n",
    "#with the quantities that are not linear already calculated\n",
    "\n",
    "bblnrgdataCut['logNrg']  = np.log10(bblnrgdataCut.nrg)\n",
    "bblnrgdataCut['logUnits']  = np.log10(bblnrgdataCut.UnitsTotal)\n",
    "\n",
    "X = np.linspace(bblnrgdataCut['logUnits'].min(), bblnrgdataCut['logUnits'].max(), 1000)\n",
    "curvemodel = smf.ols(formula = 'logNrg ~ logUnits + I(logUnits**2)', \n",
    "                          data = bblnrgdataCut).fit()\n",
    "pl.figure(figsize=(16,14))\n",
    "pl.scatter(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg))\n",
    "plot(X, curvemodel.predict(exog = dict(logUnits = X)), 'k')\n",
    "xl = pl.xlabel(\"log10 Number of Units in Building\", fontsize=20)\n",
    "yl = pl.ylabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "curvemodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# She uses the LR test to compare the linear fit and the curve fit, which she can do since they are nested models.  The corresponding LR value at a significant level of 0.05 with a chi square distribution with 1 DOF is 3.84 - if the calculated LR value is greater, we can reject the null hypothesis that the linear model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "print (\"LR : \", -2 * (linmodel_1.llf - (curvemodel.llf)))\n",
    "print (\"LR from statsmodels:\", curvemodel.compare_lr_test(linmodel_1))\n",
    "LR = curvemodel.compare_lr_test(linmodel_1)\n",
    "\n",
    "print (\"We \", end=\"\")\n",
    "if LR[0] < 3.84: #0.05 level for 1 DOF chi sq distribution \n",
    "    print (\"CANNOT\") \n",
    "    \n",
    "print (\"reject the Null hypothesis that the restricted (linear) \" + \n",
    "       \"model is better than the 2nd degree polynomial fit with p-value \", end=\"\")\n",
    "print (\"p < %.3f\"%alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
