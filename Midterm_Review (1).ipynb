{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Must Knows:\n",
    "    \n",
    "   1. Accessing Data\n",
    "     - from API\n",
    "     - Curl\n",
    "     - From URL, then move to PUIDATA\n",
    "     \n",
    "   2. MERGE MULTIPLE DATA SETS\n",
    "        - using pandas\n",
    "        - Merge on the same column\n",
    "            - may ask to do 3 sets\n",
    "        - how to remove NaN\n",
    "        - how to hande STR and INT in the same column\n",
    "        - removing blanks\n",
    "   \n",
    "   3. Plots\n",
    "        - CAPTIONS are a must for each plot\n",
    "            - caption should say: what the plot is (\"what am i looking at\")\n",
    "            - what the plot is illustrating of the data\n",
    "            - conclusion from the plot\n",
    "        - The size must be big enough to read\n",
    "        - Axis labels for X and Y\n",
    "        - Chart title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THESE ARE ALL THE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import os\n",
    "import json\n",
    "\n",
    "#imports downloader\n",
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "\n",
    "#imports function for Google API\n",
    "from get_jsonparsed_data import get_jsonparsed_data\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['ageM'].dropna(inplace = True)\n",
    "df['ageF'].dropna(inplace = True)\n",
    "\n",
    "#Syntax\n",
    "# dfname['column name'].dropna(inplace = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column and change the Date to readable value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['starttime'])\n",
    "\n",
    "#Syntax\n",
    "# dfname['new column name'] = pd.to_datetime(dfname['starttime'])\n",
    "#where 'startime' is the column whose values you want to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculating AGE by birth year and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ageM'] = 2015 - df['birth year'][(df['usertype'] == 'Subscriber') & (df['gender'] == 1)]\n",
    "df['ageF'] = 2015 - df['birth year'][(df['usertype'] == 'Subscriber') & (df['gender'] == 2)]\n",
    "\n",
    "#Syntax\n",
    "#dfname['new column name'] = 2015 - dfname['birth year column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Data - live data stream that you can access from website.  Often an API Key is required from the data developer, used in conjunction with the API link (often a special / unique link must be used).  Note the professor recommended in Assignment 1 of HW 6 that we should consider using the required base data in API format for practice, so it might be something to keep in mind for the midterm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sample code to run API data as python (.py) script (for MTA Bus Route JSON Data).  This code can be alterted for \n",
    "a more standard call implementation in a .ipynb\n",
    "'''\n",
    "\n",
    "if not len(sys.argv) == 4:  # Assignment requires 3 arguments\n",
    "    print(\"Invalid number of arguments. Run as: python  aSimplePythonScript.py YourNameHere\")\n",
    "    sys.exit()\n",
    "    \n",
    "api_key = str(sys.argv[1])\n",
    "bus_route = str(sys.argv[2])\n",
    "csv_file = str(sys.argv[3])\n",
    "\n",
    "mta_bus_api = 'http://bustime.mta.info/api/siri/vehicle-monitoring.json?key=' + api_key + \n",
    "                                            '&VehicleMonitoringDetailLevel=calls&LineRef=' + bus_route\n",
    "\n",
    "response = urllib.urlopen(mta_bus_api)\n",
    "data = response.read().decode(\"utf-8\")\n",
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Call / Download (curl -O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getzip():\n",
    "    '''\n",
    "    Function to create separate \"Manhattan\" directory within PIUdata directory (line 1), download Manhattan\n",
    "    MapPLUTO data (line 2), move the zip file to the new Manhattan subdirectory and unzip it (lines 3 and 4,\n",
    "    respectively), and remove the zip file (line 5)\n",
    "    '''\n",
    "    \n",
    "    os.system(\"mkdir \" + os.getenv(\"PUIDATA\")+\"/Manhattan\")\n",
    "    os.system(\"curl -O https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/mn_mappluto_16v1.zip\")\n",
    "    os.system(\"mv \" + \"mn_mappluto_16v1.zip \" + os.getenv(\"PUIDATA\")+\"/Manhattan\")\n",
    "    os.system(\"unzip \" + os.getenv(\"PUIDATA\") + \"/Manhattan/\" + \"mn_mappluto_16v1.zip -d \" + os.getenv(\"PUIDATA\")+\"/Manhattan\")\n",
    "    os.system(\"rm \" + os.getenv(\"PUIDATA\") + \"/Manhattan/mn_mappluto_16v1.zip\")\n",
    "\n",
    "getzip()    # run function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Test / Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `pl.plot` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_line1(x, y):\n",
    "    \"\"\"Fits a line to data properly adding the dimensions required by statsmodels\n",
    "    Arguments:\n",
    "        x: series of exogenous variables\n",
    "        y: seried of endogenous variables\n",
    "    Output:\n",
    "        slope, intercept of best fit line, and the full model fit\n",
    "    \"\"\"\n",
    "    #print x\n",
    "    X = sm.add_constant(x) #constant makes a 2-d array\n",
    "    #print X\n",
    "    model = sm.OLS(y, X, missing='drop') # ignores entires where x or y is NaN\n",
    "    fit = model.fit()\n",
    "    return fit.params[1], fit.params[0], fit # could also return stderr in each via fit.bse\n",
    "\n",
    "p1, p0, linmodel_0 = fit_line1(np.log10(bblnrgdataCut.nrg), \n",
    "                        np.log10(bblnrgdataCut.UnitsTotal))\n",
    "#since the function returns 3 arguments: slope, intercept and fit\n",
    "pl.figure(figsize=(10, 10))\n",
    "pl.scatter(np.log10(bblnrgdataCut.nrg), np.log10(bblnrgdataCut.UnitsTotal))\n",
    "plot(np.log10(bblnrgdataCut.nrg), linmodel_0.predict(), 'k')\n",
    "yl = pl.ylabel(\"log 10 Number of Units in Building\", fontsize=20)\n",
    "xl = pl.xlabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "linmodel_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_data = open(os.getenv(\"PUIDATA\")+\"/apidef.json\").read()\n",
    "myAPI = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myAPI[\"myAPI\"] # this is working \n",
    "#Remember the dictionary is the same name as the key inside, both are called myAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (os.getenv('PUIDATA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getCitiBikeCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from getCitiBikeCSV import getCitiBikeCSV\n",
    "\n",
    "# this allows you to import the function 'getCitiBikeCSV(datestring)'\n",
    "# the argument within the function is the datestring for the month of data ex (201501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Downloading', '201506')\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "datestring = '201506'\n",
    "getCitiBikeCSV(datestring)\n",
    "#os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_june = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + datestring + '-citibike-tripdata.csv')\n",
    "#df_june.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_jan = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + '201501' + '-citibike-tripdata.csv')\n",
    "#df_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(df_june.columns)\n",
    "#print(df_jan.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PLOTTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING - FOR 2 Histograms\n",
    "- Male and Female \n",
    "- HW4, Assignment 4 \"citibikes_compare_distributions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'subplots'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a22c0d77062b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Syntax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#bins = np.arange(start, stop, intervals of)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'subplots'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5682d2a7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(10, 99, 10)\n",
    "#Syntax\n",
    "#bins = np.arange(start, stop, intervals of)\n",
    "\n",
    "\n",
    "axM = df.ageM.groupby(pd.cut(df.ageM, bins)).agg([count_nonzero]).plot(kind='bar', \n",
    "                                                                legend=False)\n",
    "axM.set_title(\"male riders\")\n",
    "axF = df.ageF.groupby(pd.cut(df.ageF, bins)).agg([count_nonzero]).plot(kind='bar',\n",
    "                                                                legend=False)\n",
    "axF.set_title(\"female riders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOTTING - Cumulative Distribution\n",
    "- HW4, Assignment 4 \"citibikes_compare_distributions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csM=df.ageM.groupby(pd.cut(df.ageM, bins)).agg([count_nonzero]).cumsum()\n",
    "#Syntax\n",
    "#csM = dfname.columnname.\n",
    "\n",
    "csF=df.ageF.groupby(pd.cut(df.ageF, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "print (np.abs(csM / csM.max()-csF / csF.max()))\n",
    "\n",
    "pl.plot(bins[:-1] + 5, csM / csM.max(), label = \"M\")\n",
    "pl.plot(bins[:-1] + 5, csF / csF.max(), label = \"F\")\n",
    "pl.plot(bins[:-1] + 5, np.sqrt(csF / csF.max() - csM / csM.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST - KS\n",
    "\n",
    "#### KS Test with 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "ks = scipy.stats.ks_2samp(df.ageM[df.ageM<70], df.ageF[df.ageF<70])\n",
    "print (ks)\n",
    "\n",
    "#This produces 2 outputs, statistic and pvalue\n",
    "# if the pvalue is less than the alpa, reject the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printRejection(ksp, pv):\n",
    "    print (\"the Null hypothesis that the samples come from identical distributions \")\n",
    "\n",
    "    if ksp > pv: \n",
    "        print (\"cannot be rejected\")\n",
    "    else: \n",
    "        print (\"is rejected (p<{:.2f})\".format(pv))\n",
    "printRejection(ks[1], alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KS TEST with subsample of 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks = scipy.stats.ks_2samp(df.ageM[::200], df.ageF[::200])\n",
    "print (ks)\n",
    "printRejection(ks[1], alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS Test with subsample of 1 sample\n",
    "\n",
    "-  and plot for cumulative distro\n",
    "- Midterm Review Citibike FIT TEST on Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsample=500 #selects 1 every 500, not a random 500\n",
    "\n",
    "ksAge = stats.kstest(df_age[::subsample], 'norm', args=(df_age.mean(), df_age.std()))\n",
    "pl.title(\"cumul ditro of citibike riders\")\n",
    "pl.hist((df_age[::subsample].values), cumulative=True, normed=True, color=\"grey\")\n",
    "pl.plot(np.arange(0,80),scipy.stats.norm.cdf(np.arange(0,80), \n",
    "                                              loc=df_age.mean(),\n",
    "                                              scale=df_age.std()), color=\"red\")\n",
    "\n",
    "pl.text(0.1,-.2, ''' this is a test of \n",
    "multple line text''')\n",
    "#use color=red in the last argument for color\n",
    "#   pl.hist is the bars, pl.plot is the line\n",
    "#plt.grid() for grid on chart\n",
    "#pl.text(x,y position for the text, use nagative then ''' for multiple lines''')\n",
    "\n",
    "ksAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS - PEARSON'S\n",
    "\n",
    " - test for correlation\n",
    " - HW4, Assignment 4 \"citibikes_compare_distributions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the samples need to be cleaned off nan values \n",
    "# the samples need to be made to the same size. \n",
    "# The best option for that (least likely to bias the result) is to \n",
    "# choose Nf out of Nm values at random\n",
    "\n",
    "np.random.seed(12345)\n",
    "ageFsorted = df.ageF.sort_values()[df.ageF<70]\n",
    "ageMsorted = np.sort(np.random.choice(df.ageM[df.ageM<70], len(ageFsorted), replace=False))\n",
    "if DEBUG: \n",
    "    print (len(ageFsorted), len(ageMsorted))\n",
    "\n",
    "r_P = scipy.stats.pearsonr(ageMsorted, ageFsorted)\n",
    "print  (\"Pearson's r\" , r_P)\n",
    "\n",
    "pl.figure(figsize=(8, 8))\n",
    "pl.plot(ageMsorted, ageFsorted, label = \"Full dataset\")\n",
    "\n",
    "# this was not explicitly asked but I am redoing the test with the smaller dataset\n",
    "\n",
    "ageFsorted_short = df.ageF.sort_values()[df.ageF<70][::200]\n",
    "ageMsorted_short = np.sort(np.random.choice(df.ageM[df.ageM<70][::200], len(ageFsorted_short), replace=False))\n",
    "\n",
    "r_P = scipy.stats.pearsonr(ageMsorted, ageFsorted)\n",
    "print  (\"Pearson's r with reducted data\" , r_P)\n",
    "\n",
    "pl.plot(ageMsorted_short, ageFsorted_short, label = \"Reducted data\")\n",
    "\n",
    "pl.plot(pl.xlim(), pl.xlim(), 'k-', label=\"1-1 Age correspondence\")\n",
    "\n",
    "pl.xlabel(\"Male ages\")\n",
    "pl.ylabel(\"Female ages\")\n",
    "title = pl.title(\"Sorted ages\")\n",
    "leg = pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's Notes\n",
    "\n",
    "- Two varibales, ex age men and age women\n",
    "- Tests the correlation between them,results are from -1 to 1\n",
    "- Closer to 1 there is a postive correlation\n",
    "    - ex: as one goes up, so does the other (ex. units to nrg)\n",
    "- Closer to negative -1, negative correlation \n",
    "    - ex: as one goes up, the other goes down\n",
    " \n",
    "- Closer to 0 OR 0, there is NO correlation between the two varibales\n",
    "\n",
    "- Sometimes she refers to the result of the test as \"r\"\n",
    "- Varibales DO NOT have to be from the same data set\n",
    "- DATA MUST BE SORTED!\n",
    "\n",
    "Def From MiniTab:\n",
    "Pearson product moment correlation\n",
    "- The Pearson correlation evaluates the linear relationship between two continuous variables. A relationship is linear when a change in one variable is associated with a proportional change in the other variable.\n",
    "    - ex. you might use a Pearson correlation to evaluate whether increases in temperature at your production facility are associated with decreasing thickness of your chocolate coating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST - SPEARMAN's\n",
    "- for correlation \n",
    "- HW4, Assignment 4 \"citibikes_compare_distributions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e0613bc2cde3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mageMsorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mageFsorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mr_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#uses the sorted dfs created for the Pearsons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#OUTPUT is correlation= and , pvalue= (may be 0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "r_S = scipy.stats.spearmanr(ageMsorted, ageFsorted)\n",
    "print  (r_S)\n",
    "\n",
    "#uses the sorted dfs created for the Pearsons\n",
    "#OUTPUT is correlation= and , pvalue= (may be 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federicas Description:\n",
    "\n",
    "'''The result of the Spearman correlation is consistent with that of the Pearson's test. \n",
    "The Spearman's test is superior in our case since the Pearson's test assumes Gaussianity, and \n",
    "we have not shown that the data distributions are normal.\n",
    "The extremely low p-value indicates the extremely low probability of an uncorrelated system \n",
    "producing datasets that have a Spearman correlation at least as extreme as the one computed from these datasets.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman's Notes\n",
    "\n",
    "- a test of the linear relationship\n",
    "- Evaluated the same way as Pearson from -1 to 1\n",
    "    - Citibike result was 0.9, which demonstrates a STRONG correlation\n",
    "- sometimes she refers to the result of the test as \"r\"\n",
    "\n",
    "From Minitab:\n",
    "Spearman rank-order correlation\n",
    " - The Spearman correlation evaluates the monotonic relationship between two continuous or ordinal variables. In a monotonic relationship, the variables tend to change together, but not necessarily at a constant rate. The Spearman correlation coefficient is based on the ranked values for each variable rather than the raw data.\n",
    "\n",
    "- Spearman correlation is often used to evaluate relationships involving ordinal variables. \n",
    "\n",
    "    - ex: you might use a Spearman correlation to evaluate whether the order in which employees complete a test exercise is related to the number of months they have been employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
